{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a5f0196-9584-4f38-a3b6-a95b9091b804",
   "metadata": {},
   "source": [
    "# Probabilistic bigram model\n",
    "__Objective__: Make new names from bigram statistics.\n",
    "* Construct bigram frequencies and probabilities found in all names.\n",
    "* Sample from bigrams using `torch.Generator`\n",
    "* Implement the NLL loss function to evaluate name-likelihood of new names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e18db2-4b48-437b-bb3e-97f77b361a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89ed6e-94a4-4f5f-abc2-211170410133",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"../names.txt\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276d314-381d-492c-9a6d-433060b60e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we mean by bi-grams\n",
    "b = {} #Store bi-gram frequencies\n",
    "for word in words:\n",
    "    chars = list(\".\" + word + \".\")\n",
    "    for ch1, ch2 in zip(chars, chars[1:]):\n",
    "        bigram = (ch1,ch2)\n",
    "        b[bigram] = b.get(bigram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e48c322-369f-43ae-8361-5bac0eeb50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to create a bigram frequency\n",
    "# N[ix['i'], ix['j']] will contain the frequencies of 'ij'\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = dict([(c, i) for i, c in enumerate(['.']+chars)])\n",
    "itos = dict([(i, c) for c, i in stoi.items()])\n",
    "\n",
    "N = torch.zeros([len(chars) + 1, len(chars) + 1], dtype=torch.int32)\n",
    "\n",
    "for word in words:\n",
    "    chars = list(\".\" + word + \".\")\n",
    "    for ch1, ch2 in zip(chars, chars[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25626435-7628-4ec6-a587-41c556bceca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9229b-ad4a-4c4b-8aec-63f81b9e25b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = N[0].float()\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1710303a-7678-4b8c-8bcf-08079144fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new names by sampling from bigrams\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, 1, replacement=True, generator=g).item()\n",
    "itos[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933b5c9-3bc7-48f8-a3d2-f6f0346cd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "p = torch.rand(3, generator=g)\n",
    "p = p / p.sum()\n",
    "p\n",
    "torch.multinomial(p, num_samples=100, replacement=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1ded4d-8f66-4f67-bd33-a538940327ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing a the count matrix to avoid dividing by zero.\n",
    "# Computing a probability matrix or a likelihood matrix\n",
    "P = (N + 1).float() # in order to avoid infinite loss(NLL)\n",
    "P /= P.sum(1, keepdim=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e5297-06a9-4d64-80a3-181df68cf048",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert P[0].sum().item() == 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55448c45-7266-4840-a27f-fc3bdcd8ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, f\"{P[i, j].item():.3f}\", ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a8031-f2a5-4395-b010-1d4c3719094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sampling names from the bigram probability matrix\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "num_word = 5\n",
    "new_words = []\n",
    "\n",
    "for i in range(num_word):\n",
    "    # `name` will contain the generated name\n",
    "    word = []\n",
    "    ix = 0 #this is the index for the .* bigrams, that start a name.\n",
    "    \n",
    "    while True:\n",
    "        p = P[ix]\n",
    "        #Randomly draw a second letter, or a column\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        word.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            new_words.append(\"\".join(word))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b820fa1-8820-43c1-8c70-38afa98fd9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849384ee-faef-41ec-b6c6-f25382454c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coming up with a scoring system to evaluate the word-likeness of new words.\n",
    "#-sum(log(p))\n",
    "## Result should be:\n",
    "#\n",
    "#log_likelihood=tensor(-559951.5625)\n",
    "#nll=tensor(559951.5625)\n",
    "#2.4543561935424805\n",
    "log_likelihood = 0\n",
    "n = 0\n",
    "# Calculating the sum of likelihoods in names in `names.txt`\n",
    "for w in words:\n",
    "    chars = list(\".\" + w + \".\")\n",
    "    for ch1, ch2 in zip(chars, chars[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "print(f'{log_likelihood=}')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8658e-5bf9-460d-bc02-2d1de6518dbf",
   "metadata": {},
   "source": [
    "# Neural Network based solution\n",
    "We can try to arrove at the previous solution using a neural network.\n",
    "\n",
    "The loose framework is stoi[ch1] -> encode -> NN -> N[ix1] -> max(P[ix1]) -> itos(ix2)\n",
    "\n",
    "We need a set of weights that convert ix1-encoded to N[ix1]\n",
    "We term the N[ix1] as logits\n",
    "Use softmax to convert N[ix1] -> P[ix1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440bf54-bf4e-425d-9a23-763249db53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One input\n",
    "xs = []\n",
    "ys = []\n",
    "chars = list(\".\" + words[0] + \".\")\n",
    "for ch1, ch2 in zip(chars, chars[1:]):\n",
    "    xs.append(stoi[ch1])\n",
    "    ys.append(stoi[ch2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0913847-c7db-4adc-b480-506e86830768",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.tensor(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eccbc87-7f3b-45c2-bf34-23fa62004271",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = torch.tensor(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b690d9-8553-41b5-ba7b-0122ed8d03af",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd7db6e-d7ad-4786-80ab-20f09173af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding x.\n",
    "xenc = F.one_hot(xs, num_classes=N.shape[0]).float()\n",
    "# N[ix1]\n",
    "logits = xenc @ W\n",
    "# We use softmax to convert logits to probabilities\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3075d-a956-4511-baea-060be3394e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b9ef0-2e66-456f-bcb6-52daa9a2085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "  # i-th bigram:\n",
    "  x = xs[i].item() # input character index\n",
    "  y = ys[i].item() # label character index\n",
    "  print('--------')\n",
    "  print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "  print('input to the neural net:', x)\n",
    "  print('output probabilities from the neural net:', probs[i])\n",
    "  print('label (actual next character):', y)\n",
    "  p = probs[i, y]\n",
    "  print('probability assigned by the net to the the correct character:', p.item())\n",
    "  logp = torch.log(p)\n",
    "  print('log likelihood:', logp.item())\n",
    "  nll = -logp\n",
    "  print('negative log likelihood:', nll.item())\n",
    "  nlls[i] = nll\n",
    "\n",
    "print('=========')\n",
    "print('average negative log likelihood, i.e. loss =', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f1a70-aa0b-43ed-9673-2439bcd50336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way of arriving at this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517bf43d-1fe2-4ef9-b8c8-a1da5f87e115",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e13837-6f43-4c3e-8ef8-417629d69f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the dataset\n",
    "# One input\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    chars = list(\".\" + w + \".\")\n",
    "    for ch1, ch2 in zip(chars, chars[1:]):\n",
    "        xs.append(stoi[ch1])\n",
    "        ys.append(stoi[ch2])\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# Initializing weights\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24946c3-fa05-4046-8f2f-4b8a213b1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "epochs = 250\n",
    "step = 70\n",
    "lamda = 0.01\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    xenc = F.one_hot(xs, num_classes=27).float()\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    # Adding a regularization term here that acts like a label smoother\n",
    "    loss = -probs[torch.arange(num), ys].log().mean() + lamda * (W**2).mean()\n",
    "    print(f\"{epoch=} loss={loss.item()}\")\n",
    "    # Backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "    # Update weights\n",
    "    W.data += -step * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d58547-6dfd-45a7-aac9-7a1c73640dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, int(counts[i, j].item()), ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830d482-5740-4f7d-a532-588175ae729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sampling names from the bigram probability matrix\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "num_word = 5\n",
    "new_words = []\n",
    "\n",
    "for i in range(num_word):\n",
    "    # `name` will contain the generated name\n",
    "    word = []\n",
    "    ix = 0 #this is the index for the .* bigrams, that start a name.\n",
    "    \n",
    "    while True:\n",
    "        p = P[ix]\n",
    "        #Randomly draw a second letter, or a column\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        word.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            new_words.append(\"\".join(word))\n",
    "            break\n",
    "print(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56453833-3521-49af-a93f-9dab8635688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sampling names from neural network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "num_word = 5\n",
    "new_words = []\n",
    "\n",
    "for i in range(num_word):\n",
    "    # `name` will contain the generated name\n",
    "    word = []\n",
    "    ix = 0 #this is the index for the .* bigrams, that start a name.\n",
    "    \n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(1, keepdim=True)\n",
    "        #Randomly draw a second letter, or a column\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "        word.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            new_words.append(\"\".join(word))\n",
    "            break\n",
    "print(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32cd9a-ddfc-4ecb-a5b8-c4d81fd1d375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toynn",
   "language": "python",
   "name": "toynn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
